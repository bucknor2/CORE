[
["index.html", "Lab Notebook Section 1 Intro", " Lab Notebook Brianna Bucknor 2020-10-15 Section 1 Intro "],
["hrs-data-wrangling.html", "Section 2 HRS Data Wrangling 2.1 Attaching Data 2.2 Organizing &amp; Restructuring 2.3 Filter, Subset, and Organize", " Section 2 HRS Data Wrangling 2.1 Attaching Data #install.packages(&quot;bookdown&quot;) library(haven) HRSdataDir &lt;- &quot;C:/Users/Bri/Documents/grad-repo/grad-repo/SRP/&quot; load(paste0(HRSdataDir,&quot;PGENSCORE3A_R.RData&quot;)) #AA PGS load(paste0(HRSdataDir, &quot;PGENSCORE3E_R.RData&quot;)) #European PGS load(paste0(HRSdataDir, &quot;TRK2016TR_R.RData&quot;)) #tracker file load(paste0(HRSdataDir, &quot;H10PR.RData&quot;)) #2010 CORE preload questions load(paste0(HRSdataDir, &quot;H10LB.RData&quot;)) #2010 CORE leave behind questionaire load(paste0(HRSdataDir, &quot;H12PR.RData&quot;)) #2012 CORE preload questions load(paste0(HRSdataDir, &quot;H12LB.RData&quot;)) #2012 CORE leave behind questionaire 2.2 Organizing &amp; Restructuring #ADD GROUP VARIABLE TO PGEN EA AND AA FILES PGENSCORE3A_R$group = rep(&quot;AA&quot;,nrow(PGENSCORE3A_R)) PGENSCORE3E_R$group = rep(&quot;EA&quot;,nrow(PGENSCORE3E_R)) #MAKE SINGLE VARIABLE ID: CONCATENATE(HHID,PN) PGENSCORE3A_R$HHID_PN = paste0(PGENSCORE3A_R$HHID,PGENSCORE3A_R$PN) PGENSCORE3E_R$HHID_PN = paste0(PGENSCORE3E_R$HHID,PGENSCORE3E_R$PN) TRK2016TR_R$HHID_PN = paste0(TRK2016TR_R$HHID,TRK2016TR_R$PN) Make consistent colnames in EA and AA files # Note: edited these manually in text editor (separately AA &amp; EA just in case variables in different order) colnames(PGENSCORE3A_R) = c(&quot;HHID&quot;, &quot;PN&quot;, &quot;PC1_5A&quot;, &quot;PC1_5B&quot;, &quot;PC1_5C&quot;, &quot;PC1_5D&quot;, &quot;PC1_5E&quot;, &quot;PC6_10A&quot;, &quot;PC6_10B&quot;, &quot;PC6_10C&quot;, &quot;PC6_10D&quot;, &quot;PC6_10E&quot;, &quot;PGS3_GENCOG_CHRG15&quot;, &quot;PGS3_BMI_GIANT15&quot;, &quot;PGS3_HEIGHT_GIANT14&quot;, &quot;PGS3_SCZ_PGC14&quot;, &quot;PGS3_EDU2_SSGAC16&quot;, &quot;PGS3_EVRSMK_TAG10&quot;, &quot;PGS3_AD_IGAP13&quot;, &quot;PGS3_AD2_IGAP13&quot;, &quot;PGS3_WC_GIANT15&quot;, &quot;PGS3_WHR_GIANT15&quot;, &quot;PGS3_NEURO_SSGAC16&quot;, &quot;PGS3_WELLB_SSGAC16&quot;, &quot;PGS3_DPSYMP_SSGAC16&quot;, &quot;PGS3_CAD_CARDIOGR11&quot;, &quot;PGS3_MI_CARDIOGR15&quot;, &quot;PGS3_CRTSL_CORNET14&quot;, &quot;PGS3_T2D_DIAGRAM12&quot;, &quot;PGS3_BIP_PGC11&quot;, &quot;PGS3_ADHD_PGC17&quot;, &quot;PGS3_ADHD_PGC10&quot;, &quot;PGS3_XDISORDERPGC13&quot;, &quot;PGS3_MENARCHE_RPG14&quot;, &quot;PGS3_MENOPAUS_RPG15&quot;, &quot;PGS3_MDD_PGC13&quot;, &quot;PGS3_CPD_TAG10&quot;, &quot;PGS3_EXTRAV_GPC17&quot;, &quot;PGS3_AUTISM_PGC17&quot;, &quot;PGS3_LNGVTY_CHARG15&quot;, &quot;PGS3_AB_BROAD17&quot;, &quot;PGS3_EDU3_SSGAC18&quot;, &quot;PGS3_OCD_IOCDF17&quot;, &quot;PGS3_AFBC_SOCGEN16&quot;, &quot;PGS3_AFBF_SOCGEN16&quot;, &quot;PGS3_AFBM_SOCGEN16&quot;, &quot;PGS3_NEBC_SOCGEN16&quot;, &quot;PGS3_NEBF_SOCGEN16&quot;, &quot;PGS3_NEBM_SOCGEN16&quot;, &quot;PGS3_MDD2_PGC18&quot;, &quot;PGS3_PTSDAA_PGC18&quot;, &quot;PGS3_PTSDEA_PGC18&quot;, &quot;PGS3_PTSDC_PGC18&quot;, &quot;PGS3_HDL_GLGC13&quot;, &quot;PGS3_LDL_GLGC13&quot;, &quot;PGS3_TC_GLGC13&quot;, &quot;PGS3_ANXFS_ANGST16&quot;, &quot;PGS3_ANXCC_ANGST16&quot;, &quot;VERSION&quot;, &quot;group&quot;, &quot;HHID_PN&quot;) colnames(PGENSCORE3E_R) = c(&quot;HHID&quot;, &quot;PN&quot;, &quot;PC1_5A&quot;, &quot;PC1_5B&quot;, &quot;PC1_5C&quot;, &quot;PC1_5D&quot;, &quot;PC1_5E&quot;, &quot;PC6_10A&quot;, &quot;PC6_10B&quot;, &quot;PC6_10C&quot;, &quot;PC6_10D&quot;, &quot;PC6_10E&quot;, &quot;PGS3_GENCOG_CHRG15&quot;, &quot;PGS3_BMI_GIANT15&quot;, &quot;PGS3_HEIGHT_GIANT14&quot;, &quot;PGS3_SCZ_PGC14&quot;, &quot;PGS3_EDU2_SSGAC16&quot;, &quot;PGS3_EVRSMK_TAG10&quot;, &quot;PGS3_AD_IGAP13&quot;, &quot;PGS3_AD2_IGAP13&quot;, &quot;PGS3_WC_GIANT15&quot;, &quot;PGS3_WHR_GIANT15&quot;, &quot;PGS3_NEURO_SSGAC16&quot;, &quot;PGS3_WELLB_SSGAC16&quot;, &quot;PGS3_DPSYMP_SSGAC16&quot;, &quot;PGS3_CAD_CARDIOGR11&quot;, &quot;PGS3_MI_CARDIOGR15&quot;, &quot;PGS3_CRTSL_CORNET14&quot;, &quot;PGS3_T2D_DIAGRAM12&quot;, &quot;PGS3_BIP_PGC11&quot;, &quot;PGS3_ADHD_PGC17&quot;, &quot;PGS3_ADHD_PGC10&quot;, &quot;PGS3_XDISORDERPGC13&quot;, &quot;PGS3_MENARCHE_RPG14&quot;, &quot;PGS3_MENOPAUS_RPG15&quot;, &quot;PGS3_MDD_PGC13&quot;, &quot;PGS3_CPD_TAG10&quot;, &quot;PGS3_EXTRAV_GPC17&quot;, &quot;PGS3_AUTISM_PGC17&quot;, &quot;PGS3_LNGVTY_CHARG15&quot;, &quot;PGS3_AB_BROAD17&quot;, &quot;PGS3_EDU3_SSGAC18&quot;, &quot;PGS3_OCD_IOCDF17&quot;, &quot;PGS3_AFBC_SOCGEN16&quot;, &quot;PGS3_AFBF_SOCGEN16&quot;, &quot;PGS3_AFBM_SOCGEN16&quot;, &quot;PGS3_NEBC_SOCGEN16&quot;, &quot;PGS3_NEBF_SOCGEN16&quot;, &quot;PGS3_NEBM_SOCGEN16&quot;, &quot;PGS3_MDD2_PGC18&quot;, &quot;PGS3_PTSDAA_PGC18&quot;, &quot;PGS3_PTSDEA_PGC18&quot;, &quot;PGS3_PTSDC_PGC18&quot;, &quot;PGS3_HDL_GLGC13&quot;, &quot;PGS3_LDL_GLGC13&quot;, &quot;PGS3_TC_GLGC13&quot;, &quot;PGS3_ANXFS_ANGST16&quot;, &quot;PGS3_ANXCC_ANGST16&quot;, &quot;VERSION&quot;, &quot;group&quot;, &quot;HHID_PN&quot;) Merge AA &amp; EA PGS Files (pre-merge: AA N = 3100, EA N = 12090) PGENSCORE3 = merge(PGENSCORE3A_R,PGENSCORE3E_R, all=T) Post-merge: PGS N = 15190 Merge PGS with tracker file #All participants, even those without genotypes PGENSCORE3_TRK2016TR_ALL = merge(TRK2016TR_R,PGENSCORE3,all=T) #Only participants with genotypes PGENSCORE3_TRK2016TR_ONLY_PGS = merge(TRK2016TR_R,PGENSCORE3) Remember to split analyses by group (AA or EA) 2.3 Filter, Subset, and Organize Filtering for participants birth year, gender, race, and Enhanced Face-to-Face Interview (EFTF) assignment--which is when bio data was collected. LBY = Leave behind questionnaire library(dplyr) SRP_DATASET = dplyr::select(PGENSCORE3_TRK2016TR_ONLY_PGS, HHID, PN, HHID_PN, BIRTHYR, GENDER, RACE, EFTFASSIGN) SRP_DATASET$LBY = paste0(SRP_DATASET$HHID_PN,SRP_DATASET$EFTFASSIGN) 2010 data. H10LB_1 = as.data.frame(H10LB) H10LB_1$EFTFASSIGN =(rep(1,nrow(H10LB_1))) H10LB_1$HHID_PN = paste0(H10LB_1$HHID,H10LB_1$PN) H10LB_1$LBY = paste0(H10LB_1$HHID_PN, H10LB_1$EFTFASSIGN) 2012 data. H12LB_1 = as.data.frame(H12LB) H12LB_1$EFTFASSIGN = (rep(2,nrow(H12LB_1))) H12LB_1$HHID_PN = paste0(H12LB_1$HHID,H12LB_1$PN) H12LB_1$LBY = paste0(H12LB_1$HHID_PN, H12LB_1$EFTFASSIGN) Clean up: renaming columns names(H10LB_1) = substring(names(H10LB_1),2) colnames(H10LB_1)[1] &lt;- &quot;HHID&quot; colnames(H10LB_1)[2] &lt;- &quot;PN&quot; colnames(H10LB_1)[403] &lt;- &quot;HHID_PN&quot; colnames(H10LB_1)[404] &lt;- &quot;LBY&quot; H10LB_1 = H10LB_1[-c(402)] Selecting relevant columns. H10LB_1 = H10LB_1[-c(222:245,348:365,372:398)] H12LB_1 = H12LB_1[-c(241:243,327:334,341:346,348:483)] Filtering out those that did not complete the LB Questionnaire. 1-4 = completed by mail, with interview, other. 5 = not completed H12LB_1 = filter(H12LB_1, LBCOMP&lt;5) H10LB_1 = filter(H10LB_1, LBCOMP&lt;5) Adding year column to make it easier to calculate age and still have a record of the correct year after binding the rows. H10LB_1$YEAR = (rep(2010,nrow(H10LB_1))) H12LB_1$YEAR = (rep(2012,nrow(H12LB_1))) HLB = bind_rows(H10LB_1,H12LB_1) Joining PGS data with questionnaire data SRP_DATASET_FINAL = left_join(SRP_DATASET,HLB, by=&quot;LBY&quot;) restructuring to get education variable. SRP_DATASET_FINAL = filter(SRP_DATASET_FINAL, LBCOMP&lt;5) EDU = dplyr::select(PGENSCORE3_TRK2016TR_ONLY_PGS,HHID_PN,DEGREE) Selecting education level variable ID = dplyr::select(SRP_DATASET_FINAL, HHID_PN.x) colnames(ID) = c(&quot;HHID_PN&quot;) EDU = inner_join(EDU,ID,by=&quot;HHID_PN&quot;) EDU = dplyr:: select(EDU,-HHID_PN) Completed dataset.Finished wrangling. _A = analysis SRP_DATASET_PGS_A = inner_join(PGENSCORE3,ID, by = &quot;HHID_PN&quot;) "],
["analyses.html", "Section 3 Analyses 3.1 Constructing Resilience Measure 3.2 Regressions: brought to you by for loops &amp; lapply!", " Section 3 Analyses 3.1 Constructing Resilience Measure HRSdataDir &lt;- &quot;C:/Users/Bri/Documents/grad-repo/grad-repo/SRP/&quot; load(paste0(HRSdataDir, &quot;SRP_DATASET_FINAL_2.RData&quot;)) library(dplyr) Calculate age.Note: this is the age they were at the time they did the questionaire SRP_DATASET_FINAL$AGE = paste0(SRP_DATASET_FINAL$YEAR - SRP_DATASET_FINAL$BIRTHYR) lifetime trauma: 7 items (Q37a - Q37g) (Scale: 1= Yes, 5 = No) LFT = SRP_DATASET_FINAL[c(3,5,6,343,263,265,267,269,271,273,275)] colnames(LFT) colMeans(is.na(LFT)) Endorsement Rate participants = nrow(LFT) colSums(LFT==1,na.rm = TRUE) colSums(LFT==1,na.rm = TRUE)/(participants)&gt;0.99 #LFT &lt;- select(LFT,-$) #if any of the items are &quot;TRUE&quot;, use this line of code to reomve the item from the dataset Stressful life events: 6 items (Q38-Q38f) (Scale: 1 = Yes, 5 = No) SLE = SRP_DATASET_FINAL[c(3,284,286,288,290,292,294)] colnames(SLE) Endorsement Rate colSums(SLE==1,na.rm = TRUE) colSums(SLE==1,na.rm = TRUE)/(participants)&gt;0.99 #SLE &lt;- select(SLE,-$) #if any of the items are &quot;TRUE&quot;, use this line of code to reomve the item from the dataset Ongoing chronic stressors: 8 items (Q40a_a - Q40a_h)(Scale: 1 = No, didn't happen, 2 = Yes, but not upsetting, 3 = Yes, somewhat upsetting, 4 = Yes, very upsetting) OCS = SRP_DATASET_FINAL[c(3,305:312)] colnames(OCS) Endorsement Rate colSums(OCS==1,na.rm = TRUE) colSums(OCS==1,na.rm = TRUE)/(participants)&gt;0.99 #OCS &lt;- select(OCS,-$) #if any of the items are &quot;TRUE&quot;, use this line of code to reomve the item from the dataset PANAS: 25 item (Q27a-Q27y)(Scale: 1 = Very much, 2 = Quite a bit, 3 = Moderately, 4 = A little, 5 = Not at all). Reverse coded as per documentation. PANAS = SRP_DATASET_FINAL[c(3,139:163)] colnames(PANAS) PANAS_NA &lt;- dplyr::select(PANAS,LB027A, LB027B, LB027E, LB027I, LB027J, LB027L, LB027M, LB027N,LB027O,LB027R, LB027S,LB027W) PANAS_PA &lt;- dplyr::select(PANAS,HHID_PN.x,LB027C, LB027D, LB027F, LB027G, LB027H, LB027K, LB027P, LB027Q, LB027T,LB027U, LB027V, LB027X,LB027Y) PANAS_NA = 6 - PANAS_NA #reverse code PANAS &lt;- bind_cols(PANAS_PA,PANAS_NA) Endorsement Rate colSums(PANAS==1,na.rm = TRUE) colSums(PANAS==1,na.rm = TRUE)/(participants)&gt;0.99 #PANAS &lt;- select(PANAS,-$) #if any of the items are &quot;TRUE&quot;, use this line of code to reomve the item from the dataset Create dataset for all the phenos. Address missingness Phenos &lt;- left_join(LFT,SLE,by=&quot;HHID_PN.x&quot;) Phenos &lt;- left_join(Phenos,OCS, by = &quot;HHID_PN.x&quot;) Phenos &lt;- left_join(Phenos,PANAS, by = &quot;HHID_PN.x&quot;) Phenos$AGE &lt;- as.numeric(as.character(Phenos$AGE)) colMeans(is.na(Phenos))&gt;0.05 Scoring PANAS. Phenos$PANAS = rowMeans(PANAS[,c(&quot;LB027A&quot;, &quot;LB027B&quot;, &quot;LB027C&quot;, &quot;LB027D&quot;, &quot;LB027E&quot;, &quot;LB027F&quot;, &quot;LB027G&quot;, &quot;LB027H&quot;, &quot;LB027I&quot;,&quot;LB027J&quot;, &quot;LB027K&quot;, &quot;LB027L&quot;,&quot;LB027M&quot;,&quot;LB027N&quot;, &quot;LB027O&quot;, &quot;LB027P&quot;, &quot;LB027Q&quot;, &quot;LB027R&quot;, &quot;LB027S&quot;, &quot;LB027T&quot;, &quot;LB027U&quot;, &quot;LB027V&quot;,&quot;LB027W&quot;, &quot;LB027X&quot;,&quot;LB027Y&quot;)],na.rm = TRUE) Phenos &lt;- Phenos[-c(26:50)] names(Phenos)[names(Phenos) == &#39;HHID_PN.x&#39;] &lt;- &#39;HHID_PN&#39; complete = na.omit(Phenos) resilience &lt;- lm(PANAS~.-HHID_PN, data=complete) resilience_resid &lt;- as.data.frame(rstandard(resilience)) colnames(resilience_resid) &lt;- c(&quot;resilience&quot;) resilience_resid = resilience_resid * -1 res_data = bind_cols(complete,resilience_resid) res_data = dplyr::select(res_data,HHID_PN , resilience) PGS_data = inner_join(SRP_DATASET_PGS_A,res_data,by=&quot;HHID_PN&quot;) d_E = filter(PGS_data,group==&quot;EA&quot;) d_AA = filter(PGS_data, group==&quot;AA&quot;) 3.2 Regressions: brought to you by for loops &amp; lapply! pgs = c(&quot;PGS3_HEIGHT_GIANT14&quot;,&quot;PGS3_WC_GIANT15&quot;,&quot;PGS3_AD_IGAP13&quot;, &quot;PGS3_GENCOG_CHRG15&quot;, &quot;PGS3_SCZ_PGC14&quot;,&quot;PGS3_EVRSMK_TAG10&quot;,&quot;PGS3_WELLB_SSGAC16&quot;,&quot;PGS3_NEURO_SSGAC16&quot;,&quot;PGS3_DPSYMP_SSGAC16&quot;,&quot;PGS3_CPD_TAG10&quot;,&quot;PGS3_CAD_CARDIOGR11&quot;,&quot;PGS3_MI_CARDIOGR15&quot;,&quot;PGS3_T2D_DIAGRAM12&quot;,&quot;PGS3_ADHD_PGC17&quot;,&quot;PGS3_AUTISM_PGC17&quot;,&quot;PGS3_BIP_PGC11&quot;,&quot;PGS3_XDISORDERPGC13&quot;,&quot;PGS3_MENARCHE_RPG14&quot;,&quot;PGS3_MENOPAUS_RPG15&quot;,&quot;PGS3_CRTSL_CORNET14&quot;,&quot;PGS3_EXTRAV_GPC17&quot;,&quot;PGS3_AB_BROAD17&quot;,&quot;PGS3_EDU3_SSGAC18&quot;,&quot;PGS3_OCD_IOCDF17&quot;,&quot;PGS3_AFBC_SOCGEN16&quot;, &quot;PGS3_AFBF_SOCGEN16&quot;, &quot;PGS3_AFBM_SOCGEN16&quot;,&quot;PGS3_MDD2_PGC18&quot;, &quot;PGS3_PTSDAA_PGC18&quot;, &quot;PGS3_PTSDEA_PGC18&quot;, &quot;PGS3_PTSDC_PGC18&quot;,&quot;PGS3_ANXFS_ANGST16&quot;) Use a for loop to start setting up the model to run the regression on. Here, each pgs of interest is being joined up with the columns needed for the model and grouped into a list. each item in the list is then named to match the pgs of interest. for (p in pgs){ assign(paste0(p, sep =&quot;&quot;),subset(d_AA, select = c(&quot;resilience&quot;, &quot;PC1_5A&quot;, &quot;PC1_5B&quot;, &quot;PC1_5C&quot;, &quot;PC1_5D&quot;, &quot;PC1_5E&quot;,p))) } pgs.list.AA = list(PGS3_HEIGHT_GIANT14= PGS3_HEIGHT_GIANT14, PGS3_WC_GIANT15= PGS3_WC_GIANT15, PGS3_AD_IGAP13= PGS3_AD_IGAP13, PGS3_GENCOG_CHRG15 = PGS3_GENCOG_CHRG15, PGS3_SCZ_PGC14 = PGS3_SCZ_PGC14, PGS3_EVRSMK_TAG10= PGS3_EVRSMK_TAG10, PGS3_WELLB_SSGAC16= PGS3_WELLB_SSGAC16, PGS3_NEURO_SSGAC16= PGS3_NEURO_SSGAC16, PGS3_DPSYMP_SSGAC16= PGS3_DPSYMP_SSGAC16, PGS3_CPD_TAG10= PGS3_CPD_TAG10, PGS3_CAD_CARDIOGR11= PGS3_CAD_CARDIOGR11, PGS3_MI_CARDIOGR15= PGS3_MI_CARDIOGR15, PGS3_T2D_DIAGRAM12= PGS3_T2D_DIAGRAM12, PGS3_ADHD_PGC17= PGS3_ADHD_PGC17, PGS3_AUTISM_PGC17= PGS3_AUTISM_PGC17, PGS3_BIP_PGC11= PGS3_BIP_PGC11, PGS3_XDISORDERPGC13= PGS3_XDISORDERPGC13, PGS3_MENARCHE_RPG14= PGS3_MENARCHE_RPG14, PGS3_MENOPAUS_RPG15= PGS3_MENOPAUS_RPG15, PGS3_CRTSL_CORNET14= PGS3_CRTSL_CORNET14, PGS3_EXTRAV_GPC17= PGS3_EXTRAV_GPC17, PGS3_AB_BROAD17= PGS3_AB_BROAD17, PGS3_EDU3_SSGAC18= PGS3_EDU3_SSGAC18, PGS3_OCD_IOCDF17= PGS3_OCD_IOCDF17, PGS3_AFBC_SOCGEN16= PGS3_AFBC_SOCGEN16, PGS3_AFBF_SOCGEN16 = PGS3_AFBF_SOCGEN16, PGS3_AFBM_SOCGEN16 = PGS3_AFBM_SOCGEN16, PGS3_MDD2_PGC18= PGS3_MDD2_PGC18, PGS3_PTSDAA_PGC18 = PGS3_PTSDAA_PGC18, PGS3_PTSDEA_PGC18 = PGS3_PTSDEA_PGC18, PGS3_PTSDC_PGC18 = PGS3_PTSDC_PGC18, PGS3_ANXFS_ANGST16= PGS3_ANXFS_ANGST16) for (p in pgs){ assign(paste0(p, sep =&quot;&quot;),subset(d_E, select = c(&quot;resilience&quot;, &quot;PC1_5A&quot;, &quot;PC1_5B&quot;, &quot;PC1_5C&quot;, &quot;PC1_5D&quot;, &quot;PC1_5E&quot;,p))) } pgs.list.E = list(PGS3_HEIGHT_GIANT14= PGS3_HEIGHT_GIANT14, PGS3_WC_GIANT15= PGS3_WC_GIANT15, PGS3_AD_IGAP13= PGS3_AD_IGAP13, PGS3_GENCOG_CHRG15 = PGS3_GENCOG_CHRG15, PGS3_SCZ_PGC14 = PGS3_SCZ_PGC14, PGS3_EVRSMK_TAG10= PGS3_EVRSMK_TAG10, PGS3_WELLB_SSGAC16= PGS3_WELLB_SSGAC16, PGS3_NEURO_SSGAC16= PGS3_NEURO_SSGAC16, PGS3_DPSYMP_SSGAC16= PGS3_DPSYMP_SSGAC16, PGS3_CPD_TAG10= PGS3_CPD_TAG10, PGS3_CAD_CARDIOGR11= PGS3_CAD_CARDIOGR11, PGS3_MI_CARDIOGR15= PGS3_MI_CARDIOGR15, PGS3_T2D_DIAGRAM12= PGS3_T2D_DIAGRAM12, PGS3_ADHD_PGC17= PGS3_ADHD_PGC17, PGS3_AUTISM_PGC17= PGS3_AUTISM_PGC17, PGS3_BIP_PGC11= PGS3_BIP_PGC11, PGS3_XDISORDERPGC13= PGS3_XDISORDERPGC13, PGS3_MENARCHE_RPG14= PGS3_MENARCHE_RPG14, PGS3_MENOPAUS_RPG15= PGS3_MENOPAUS_RPG15, PGS3_CRTSL_CORNET14= PGS3_CRTSL_CORNET14, PGS3_EXTRAV_GPC17= PGS3_EXTRAV_GPC17, PGS3_AB_BROAD17= PGS3_AB_BROAD17, PGS3_EDU3_SSGAC18= PGS3_EDU3_SSGAC18, PGS3_OCD_IOCDF17= PGS3_OCD_IOCDF17, PGS3_AFBC_SOCGEN16= PGS3_AFBC_SOCGEN16, PGS3_AFBF_SOCGEN16 = PGS3_AFBF_SOCGEN16, PGS3_AFBM_SOCGEN16 = PGS3_AFBM_SOCGEN16, PGS3_MDD2_PGC18= PGS3_MDD2_PGC18, PGS3_PTSDAA_PGC18 = PGS3_PTSDAA_PGC18, PGS3_PTSDEA_PGC18 = PGS3_PTSDEA_PGC18, PGS3_PTSDC_PGC18 = PGS3_PTSDC_PGC18, PGS3_ANXFS_ANGST16= PGS3_ANXFS_ANGST16) Use lapply to perform regression on all the models set up in pgs.list model.AA = lapply(pgs.list.AA, function(x)lm(resilience ~ x[[7]]+ PC1_5A + PC1_5B + PC1_5C + PC1_5D + PC1_5E, data = x)) model.E = lapply(pgs.list.E, function(x)lm(resilience ~ x[[7]]+ PC1_5A + PC1_5B + PC1_5C + PC1_5D + PC1_5E, data = x)) "],
["graphs.html", "Section 4 Graphs", " Section 4 Graphs "],
["prelim-prep.html", "Section 5 Prelim Prep 5.1 Task List: 5.2 Measuring Resilience", " Section 5 Prelim Prep 5.1 Task List: ☑ Request UKB data ☑ Put together rough draft of survey ☑ Request CD-RISC access ☑ Send committee member requests ☐ Work on outline (Scrivener?) ☑ Set up new Git repo ☐ Bioinformatic/annotation decisions(Aim 3) SNP+based enrichment analysis GTEx Genome Browser SNPnexus VarioWatch etc. 5.2 Measuring Resilience Take the survey PDF of survey "],
["drafting.html", "Section 6 Drafting Specific Aims 6.1 Chapter 1: Introduction 6.2 Chapter 2: Background and Significance 6.3 Chapter 3: Study 1 - Validation of Resilience Measure 6.4 Chapter 4: Study 2 - GWAS of Resilience 6.5 Chapter 5: Study 3 - Biological &amp; Functional Annotation 6.6 Chapter 6: ????", " Section 6 Drafting Specific Aims Psychological resilience can be defined as one’s ability to successfully cope in the face of stress and trauma and either maintain a pre-stress level of psychological and physiological functioning or quickly return to it. Studies of resilience have identified it to be a multifaceted trait influenced by factors such as social support, socioeconomic status, successful termination of stress responses, and developmental timing of stress. Resilience has also been identified to be moderately heritable, evidencing a genetic component to the trait. While there is support for the influence of genetics in resilience, the genetic variants that contribute to the observed heritability are not well understood. In order to address this gap in knowledge, I propose a robust, large-scale genome-wide association study (GWAS) of resilience as well as follow-up analyses to investigate the polygenic nature of resilience further. In order to accomplish the proposed research, I will make use of secondary data available through UK Biobank. UK Biobank is a large population-based cohort that consists of survey data, which will allow for the construction of the resilience measure, as well as provide the genetic data needed to perform the GWAS. In addition, the identification of genetic variants will allow for further investigation of the extent to which their associated genes aggregate within influential pathways. Importantly, understanding the genetics of resilience can also contribute to the development of mechanism-focused interventions for those who are at increased risk for the development of psychopathology. In order to accomplish the goals of this project, I propose three specific aims: Aim 1: Validate Scoring Algorithm to Convert Widely Available Psychological Assessments into Resiliency via Comparison with Established Measure Using a Large Online Sample As resilience is not directly measured in any existing large-scale genetic dataset, the first aim of the project is to validate my operational definition of resilience. Taking steps to validate the measure helps to ensure the GWAS will be as robust as possible, as measurement inaccuracies can result in unreliable results. Resilience will be operationalized as negative affect residualized over stress and trauma. These measures will be obtained from survey data available through UK Biobank. In order to validate this construct of resilience, I will test it within a sample of the general population and assess how strongly it correlates with the Connor-Davidson Resilience Scale, the most commonly used measure of resilience. I hypothesize that they will be strongly correlated based on my recent exploratory study of polygenic proxies of resilience, which found this to be a robust operationalization of resilience. Aim 2: Perform a Genome-Wide Association Study of Resilience in the UK Biobank (N &gt; 150,000) In order to identify genetic variants associated with resilience, I will perform a genome-wide association study (GWAS). To date, only one GWAS of resilience has been done but was limited by its sample size and generalizability. The proposed GWAS of resilience will improve on the one previously performed by leveraging a large sample size (N &gt; 150,000) and a population-based cohort. The UK Biobank data will undergo seven specific quality control procedures before conducting the genome-wide association analyses. The results of the GWAS will identify which genetic variants (i.e., single nucleotide polymorphisms) are significantly associated with resilience at P &lt; 5×10−8. These significant single nucleotide polymorphisms (SNPs) will then undergo further analyses in aim three, to better understand their relationship with resilience. Aim 3: Follow-up Analyses of GWAS Results to Investigate Biological Relevance and Polygenic Nature Following the GWAS of resilience, analyses will be performed to provide context and a greater understanding of the SNPs that were identified as being significantly associated with resilience. In this third aim, two follow-up analyses will be conducted. The first of which will be a SNP annotation, to provide genetic context for the SNPs. The second will be the construction of a polygenic risk score. In an independent replication sample, polygenic scores will be constructed by aggregating resilience associated SNPs to produce a single polygenic risk score of resilience. Once constructed, this score can then be used to predict individual resiliency. Together, these aims will further our understanding of the genetics of resilience and move towards potential biological mechanisms that can be acted on to produce better mental health outcomes in those exposed to stress or trauma. 6.1 Chapter 1: Introduction Brief overview 6.2 Chapter 2: Background and Significance 6.2.1 Defining Psychological Resilience 6.2.2 Current understanding of the Genetics of Resilience 6.2.3 Gap in knowledge/Dearth of research 6.2.4 Proposal 6.3 Chapter 3: Study 1 - Validation of Resilience Measure 6.3.1 Challenges to Resilience Measurment 6.3.2 Importance of Measurement &amp; Validation 6.3.3 Approach for the proposed study 6.4 Chapter 4: Study 2 - GWAS of Resilience 6.4.1 Rationale for a GWAS of Resilience Echo parts from Section @ref(S:Gap in knowledge/Dearth of research) 6.4.2 Approach for proposed study 6.5 Chapter 5: Study 3 - Biological &amp; Functional Annotation 6.6 Chapter 6: ???? "]
]
